{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Word Embedding Quality Benchmark Tools are spereated in different evaluation methods. To apply an evaluation method from the `SeaQube` Package, it is needed to provide the NLP model in the correct format. Details about this topic can be found in the `nlp` Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some tools\n",
    "from seaqube.tools.io import load_json\n",
    "from os.path import join\n",
    "from seaqube.nlp.seaqube_model import SeaQuBeCompressLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre trained (small) model, in the seaqube format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = main_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = SeaQuBeCompressLoader.load_compressed_model(join(main_path, \"example_model_compressed.dill\"), \"example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json,urllib.request\n",
    "data = urllib.request.urlopen(\"https://raw.githubusercontent.com/bees4ever/SeaQuBe/master/examples/sick_full_corpus.json\").read()\n",
    "\n",
    "corpus = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import tools\n",
    "from seaqube.benchmark.wordanalogy import WordAnalogyBenchmark\n",
    "from seaqube.benchmark.wordsimilarity import WordSimilarityBenchmark\n",
    "from seaqube.benchmark.wordoutliers import WordOutliersBenchmark\n",
    "from seaqube.benchmark.semantic_wordnet import SemanticWordnetBenchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to install `vec4ir`, this can be done trough \"SeaQuBe\":\n",
    "# from seaqube.benchmark.corpus4ir import WordCentroidSimilarityBenchmark\n",
    "from seaqube import download;download('vec4ir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vec4ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load module\n",
    "from seaqube.benchmark.corpus4ir import WordCentroidSimilarityBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform semantical tests\n",
    "wsb = WordSimilarityBenchmark(test_set='simlex999')\n",
    "print(wsb(nlp.model))  # score=0.008905456556563954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wab = WordAnalogyBenchmark('google-analogies')\n",
    "print(wab(nlp.model))  # score=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wob = WordOutliersBenchmark('wikisem500')\n",
    "print(wob(nlp.model))  # score=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c4ir = WordCentroidSimilarityBenchmark(corpus[0:200])  # need the original corpus for setting up IR\n",
    "print(c4ir(nlp.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The semantic word net benchmark needs a base of word pairs. This pairs can be generated easily:\n",
    "vocabs = nlp.vocab()\n",
    "vocabs = vocabs[0:200]\n",
    "\n",
    "word_pairs, length = SemanticWordnetBenchmark.word_pairs_from_vocab_list(vocabs)\n",
    "print(\"Pairs Length:\", length)\n",
    "\n",
    "swb = SemanticWordnetBenchmark(word_pairs, False)\n",
    "print(swb(nlp.model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
